{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstmad.vrae import VRAE\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from lstmad.lstmae import RecurrentAutoencoder, train_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_SEED = 666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 90\n",
    "hidden_layer_depth = 1\n",
    "latent_length = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "n_epochs = 40\n",
    "dropout_rate = 0.2\n",
    "optimizer = 'Adam' # options: ADAM, SGD\n",
    "cuda = True # options: True, False\n",
    "print_every=30\n",
    "clip = True # options: True, False\n",
    "max_grad_norm=5\n",
    "loss = 'MSELoss' # options: SmoothL1Loss, MSELoss\n",
    "block = 'LSTM' # options: LSTM, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/ECG5000_TRAIN.txt',\n",
    "                       sep=' ',skipinitialspace=True,\n",
    "                       header=None,\n",
    "                       names=['target'] + list(range(0,140)))\n",
    "\n",
    "test_df = pd.read_csv('data/ECG5000_TEST.txt',\n",
    "                       sep=' ',skipinitialspace=True,\n",
    "                       header=None,\n",
    "                       names=['target'] + list(range(0,140)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.append(test_df)\n",
    "df = df.sample(frac=1.0)\n",
    "df.target -=1\n",
    "y = df['target']\n",
    "X = df.drop(labels='target', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "  X, y,\n",
    "  test_size=0.3,\n",
    "  random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "val_X, test_X, val_y, test_y = train_test_split(\n",
    "  val_X, val_y,\n",
    "  test_size=0.5, \n",
    "  random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    sequences = df.astype(np.float32).to_numpy().tolist()\n",
    "    dataset = [torch.tensor(s).unsqueeze(1).float() for s in sequences]\n",
    "    n_seq, seq_len, n_features = torch.stack(dataset).shape\n",
    "    return dataset, seq_len, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, seq_len, n_features = create_dataset(train_X)\n",
    "val_dataset, _, _ = create_dataset(val_X)\n",
    "test_dataset, _, _ = create_dataset(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentAutoencoder(seq_len, n_features, device, 8)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model,train_dataset,val_dataset, 50 , device)\n",
    "# torch.save(model.state_dict(), 'autoencoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('autoencoder.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors, validation_errors, test_errors = [], [], []\n",
    "loss_f = torch.nn.L1Loss(reduction='sum').to(device)\n",
    "model = model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for seq_true in train_dataset:\n",
    "        seq_true = seq_true.to(device)\n",
    "        z, seq_pred = model(seq_true)\n",
    "        loss = loss_f(seq_pred, seq_true)\n",
    "        train_errors.append(loss.item())\n",
    "    \n",
    "    for seq_true in val_dataset:\n",
    "        seq_true = seq_true.to(device)\n",
    "        z, seq_pred = model(seq_true)\n",
    "        loss = loss_f(seq_pred, seq_true)\n",
    "        validation_errors.append(loss.item())\n",
    "        \n",
    "    for seq_true in test_dataset:\n",
    "        seq_true = seq_true.to(device)\n",
    "        z, seq_pred = model(seq_true)\n",
    "        loss = loss_f(seq_pred, seq_true)\n",
    "        test_errors.append(loss.item())\n",
    "        \n",
    "train_errors = np.array(train_errors)\n",
    "validation_errors = np.array(validation_errors)\n",
    "test_errors = np.array(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.79403745888497"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_errors,bins=20)\n",
    "train_errors.mean() + 3 * train_errors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.21844665327109"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(validation_errors,bins=20)\n",
    "validation_errors.mean() + 3 * validation_errors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.47623963655548"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQsklEQVR4nO3dbYylZX3H8e+vLMX6EAF33K67mwzVrQZNXciEQvQFlSqIxsXEkiVGt5ZmfQEpNiQGNKmalARTlWqitKtQVkNBilg2SLW4khhfCA6Iy8NKWWWR3SzsqIi2pkbw3xfn3nC6zO48nDOcM1zfT3Iy931d933O/zr3zPzmfpqTqkKS1J7fG3UBkqTRMAAkqVEGgCQ1ygCQpEYZAJLUqBWjLgBg5cqVNTk5OeoyJGlZueuuu35aVROLXX8sAmBycpLp6elRlyFJy0qSRwZZ30NAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUqLG4E3iUJi/52qLX3XP524ZYiSQ9t9wDkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNmjMAkrwgyZ1JfpDk/iQf69pPSHJHkt1Jvpzk97v2Y7r53V3/5NIOQZK0GPPZA/gN8Kaqej2wATgryanAx4ErqupVwBPA+d3y5wNPdO1XdMtJksbMnAFQPf/dzR7dPQp4E3Bj174NOKeb3tjN0/WfkSRDq1iSNBTzOgeQ5Kgk9wAHgNuAHwG/qKqnukX2Amu66TXAowBd/5PAy4ZZtCRpcPMKgKp6uqo2AGuBU4DXDPrCSbYkmU4yPTMzM+jTSZIWaEFXAVXVL4DbgdOAY5Mc/EzhtcC+bnofsA6g638p8LNZnmtrVU1V1dTExMQiy5ckLdZ8rgKaSHJsN/0HwJuBXfSC4F3dYpuBm7vp7d08Xf+3qqqGWbQkaXAr5l6E1cC2JEfRC4wbquqWJA8A1yf5e+D7wFXd8lcBX0qyG/g5sGkJ6pYkDWjOAKiqncBJs7T/mN75gEPb/xf4i6FUJ0laMt4JLEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKj5gyAJOuS3J7kgST3J7moa/9okn1J7ukeZ/etc2mS3UkeTHLmUg5AkrQ4K+axzFPAxVV1d5KXAHclua3ru6KqPtG/cJITgU3Aa4FXAN9M8sdV9fQwC5ckDWbOPYCq2l9Vd3fTvwJ2AWuOsMpG4Pqq+k1VPQzsBk4ZRrGSpOFZ0DmAJJPAScAdXdOFSXYmuTrJcV3bGuDRvtX2MktgJNmSZDrJ9MzMzIILlyQNZt4BkOTFwFeAD1TVL4ErgVcCG4D9wCcX8sJVtbWqpqpqamJiYiGrSpKGYF4BkORoer/8r62qmwCq6vGqerqqfgd8nmcO8+wD1vWtvrZrkySNkflcBRTgKmBXVX2qr31132LvBO7rprcDm5Ick+QEYD1w5/BKliQNw3yuAnoD8B7g3iT3dG0fAs5LsgEoYA/wfoCquj/JDcAD9K4gusArgCRp/MwZAFX1HSCzdN16hHUuAy4boC5J0hLzTmBJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktSoOQMgyboktyd5IMn9SS7q2o9PcluSh7qvx3XtSfKZJLuT7Exy8lIPQpK0cPPZA3gKuLiqTgROBS5IciJwCbCjqtYDO7p5gLcC67vHFuDKoVctSRrYnAFQVfur6u5u+lfALmANsBHY1i22DTinm94IfLF6vgscm2T10CuXJA1kQecAkkwCJwF3AKuqan/X9RiwqpteAzzat9reru3Q59qSZDrJ9MzMzALLliQNat4BkOTFwFeAD1TVL/v7qqqAWsgLV9XWqpqqqqmJiYmFrCpJGoJ5BUCSo+n98r+2qm7qmh8/eGin+3qga98HrOtbfW3XJkkaI/O5CijAVcCuqvpUX9d2YHM3vRm4ua/9vd3VQKcCT/YdKpIkjYkV81jmDcB7gHuT3NO1fQi4HLghyfnAI8C5Xd+twNnAbuDXwPuGWrEkaSjmDICq+g6Qw3SfMcvyBVwwYF2SpCXmncCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVHz+TyAsTZ5yddGXYIkLUvuAUhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaNWcAJLk6yYEk9/W1fTTJviT3dI+z+/ouTbI7yYNJzlyqwiVJg5nPHsA1wFmztF9RVRu6x60ASU4ENgGv7db5XJKjhlWsJGl45gyAqvo28PN5Pt9G4Pqq+k1VPQzsBk4ZoD5J0hIZ5BzAhUl2doeIjuva1gCP9i2zt2t7liRbkkwnmZ6ZmRmgDEnSYiw2AK4EXglsAPYDn1zoE1TV1qqaqqqpiYmJRZYhSVqsRQVAVT1eVU9X1e+Az/PMYZ59wLq+Rdd2bZKkMbOoAEiyum/2ncDBK4S2A5uSHJPkBGA9cOdgJUqSlsKcnweQ5DrgdGBlkr3AR4DTk2wACtgDvB+gqu5PcgPwAPAUcEFVPb00pUuSBjFnAFTVebM0X3WE5S8DLhukKEnS0vNOYElqlAEgSY1a9p8JPEqDfB7xnsvfNsRKJGnh3AOQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGjVnACS5OsmBJPf1tR2f5LYkD3Vfj+vak+QzSXYn2Znk5KUsXpK0ePPZA7gGOOuQtkuAHVW1HtjRzQO8FVjfPbYAVw6nTEnSsM0ZAFX1beDnhzRvBLZ109uAc/rav1g93wWOTbJ6WMVKkoZnsecAVlXV/m76MWBVN70GeLRvub1d27Mk2ZJkOsn0zMzMIsuQJC3WwCeBq6qAWsR6W6tqqqqmJiYmBi1DkrRAiw2Axw8e2um+Huja9wHr+pZb27VJksbMYgNgO7C5m94M3NzX/t7uaqBTgSf7DhVJksbIirkWSHIdcDqwMsle4CPA5cANSc4HHgHO7Ra/FTgb2A38GnjfEtQsSRqCOQOgqs47TNcZsyxbwAWDFiVJWnreCSxJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhq1YpCVk+wBfgU8DTxVVVNJjge+DEwCe4Bzq+qJwcqUJA3bMPYA/qyqNlTVVDd/CbCjqtYDO7p5SdKYWYpDQBuBbd30NuCcJXgNSdKABg2AAv4zyV1JtnRtq6pqfzf9GLBqthWTbEkynWR6ZmZmwDIkSQs10DkA4I1VtS/Jy4Hbkvywv7OqKknNtmJVbQW2AkxNTc26jCRp6Qy0B1BV+7qvB4CvAqcAjydZDdB9PTBokZKk4Vt0ACR5UZKXHJwG3gLcB2wHNneLbQZuHrRISdLwDXIIaBXw1SQHn+dfq+rrSb4H3JDkfOAR4NzBy5QkDduiA6Cqfgy8fpb2nwFnDFKUJGnpeSewJDXKAJCkRhkAktSoQe8D0CJNXvK1Ra+75/K3DbESSa1yD0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEZ5H8AyNMg9BOB9BJJ63AOQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlR3geg54yfgSCNFwNACzLoTWiSxocB0KDWfol757Q0O88BSFKjlmwPIMlZwKeBo4AvVNXlS/Vaev4b5V6L5y70fLUkAZDkKOCzwJuBvcD3kmyvqgeW4vWk56NRBY+HzNqxVHsApwC7q+rHAEmuBzYCBoCa0tr5lkEt19AbxCgDM1U1/CdN3gWcVVV/3c2/B/jTqrqwb5ktwJZu9tXAg0MvZPhWAj8ddREDcgzjYbmPYbnXD8+PMby6ql6y2JVHdhVQVW0Fto7q9RcjyXRVTY26jkE4hvGw3Mew3OuH588YBll/qa4C2ges65tf27VJksbEUgXA94D1SU5I8vvAJmD7Er2WJGkRluQQUFU9leRC4Bv0LgO9uqruX4rXeo4tq0NWh+EYxsNyH8Nyrx8cw9KcBJYkjT/vBJakRhkAktQoA+AwkqxLcnuSB5Lcn+Sirv34JLcleaj7etyoaz2SJEcl+X6SW7r5E5LckWR3ki93J+nHVpJjk9yY5IdJdiU5bRlug7/tvofuS3JdkheM+3ZIcnWSA0nu62ub9X1Pz2e6sexMcvLoKn/GYcbwD9330s4kX01ybF/fpd0YHkxy5miq/v9mG0Nf38VJKsnKbn7B28EAOLyngIur6kTgVOCCJCcClwA7qmo9sKObH2cXAbv65j8OXFFVrwKeAM4fSVXz92ng61X1GuD19MaybLZBkjXA3wBTVfU6ehdFbGL8t8M1wFmHtB3ufX8rsL57bAGufI5qnMs1PHsMtwGvq6o/Af4LuBSg+9neBLy2W+dz3b+0GbVrePYYSLIOeAvwk77mhW+HqvIxjwdwM73/bfQgsLprWw08OOrajlDzWno/qG8CbgFC787HFV3/acA3Rl3nEep/KfAw3cUKfe3LaRusAR4Fjqd31d0twJnLYTsAk8B9c73vwD8D58223Kgfh47hkL53Atd205cCl/b1fQM4bdT1H24MwI30/iDaA6xc7HZwD2AekkwCJwF3AKuqan/X9RiwakRlzcc/Ah8EftfNvwz4RVU91c3vpfcLalydAMwA/9IdxvpCkhexjLZBVe0DPkHvL7X9wJPAXSyv7XDQ4d73gyF30HIZz18B/9FNL5sxJNkI7KuqHxzSteAxGABzSPJi4CvAB6rql/191YvZsbyONsnbgQNVddeoaxnACuBk4MqqOgn4Hw453DPO2wCgO06+kV6YvQJ4EbPs0i834/6+zyXJh+kd5r121LUsRJIXAh8C/m4Yz2cAHEGSo+n98r+2qm7qmh9PsrrrXw0cGFV9c3gD8I4ke4Dr6R0G+jRwbJKDNwCO+7/o2Avsrao7uvkb6QXCctkGAH8OPFxVM1X1W+AmettmOW2Hgw73vi+rf/2S5C+BtwPv7oIMls8YXknvj4kfdD/ba4G7k/whixiDAXAYSQJcBeyqqk/1dW0HNnfTm+mdGxg7VXVpVa2tqkl6J7e+VVXvBm4H3tUtNrb1A1TVY8CjSV7dNZ1B71+KL4tt0PkJcGqSF3bfUwfHsGy2Q5/Dve/bgfd2V6GcCjzZd6horKT3QVUfBN5RVb/u69oObEpyTJIT6J1IvXMUNR5JVd1bVS+vqsnuZ3svcHL3s7Lw7TDqExzj+gDeSG8XdydwT/c4m95x9B3AQ8A3geNHXes8xnI6cEs3/Uf0vrF3A/8GHDPq+uaofQMw3W2HfweOW27bAPgY8EPgPuBLwDHjvh2A6+ids/ht90vm/MO97/QuLvgs8CPgXnpXPI3rGHbTO05+8Gf6n/qW/3A3hgeBt466/sON4ZD+PTxzEnjB28F/BSFJjfIQkCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjfo/j7vnhAv+XkAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_errors,bins=20)\n",
    "test_errors.mean() + 3 * test_errors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 0., 0., 0., 0., 2., 4., 1., 0., 1., 4., 0., 1., 3., 4., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.values[validation_errors >= validation_errors.mean() + 3 * validation_errors.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 4., 4., 0., 0., 1., 0.,\n",
       "       4., 3., 2., 0., 3., 0., 0., 2., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.values[test_errors >= validation_errors.mean() + 3 * validation_errors.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2., 1., 2., 0., 1., 0., 3., 4., 1., 1., 2., 2., 1., 1., 4.,\n",
       "       3., 1., 1., 1., 3., 0., 0., 0., 0., 1., 4., 1., 1., 1., 3., 0., 0.,\n",
       "       0., 4., 0., 1., 0., 1., 0., 0., 0., 0., 3., 2., 2., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 4., 0., 0., 1., 4., 0., 0., 2., 3., 1., 0., 0., 3., 1.,\n",
       "       1., 1., 1., 2., 2., 0., 1., 1., 0., 2., 1., 1., 1., 0., 2., 0., 1.,\n",
       "       2., 2., 2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.values[train_errors >= validation_errors.mean() + 3 * validation_errors.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyScoreProcessor(nn.Module):\n",
    "\n",
    "    def __init__(self, autoencoder, autoencoder_latent_dim, hidden_layer_dim, device):\n",
    "        super(AnomalyScoreProcessor, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        for param in autoencoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.hidden_layer_dim = hidden_layer_dim\n",
    "        self.hidden_layer = torch.nn.Linear(autoencoder_latent_dim + 1 , hidden_layer_dim).to(device)\n",
    "        self.relu = torch.nn.ReLU().to(device)\n",
    "        self.loss = nn.L1Loss(reduction='sum').to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, out =  self.autoencoder(x)\n",
    "        anomaly_score = torch.abs(self.loss(out, x))\n",
    "        concatenated_tensor = torch.cat((z, anomaly_score.reshape(1, 1)), dim=1)\n",
    "        h = self.hidden_layer(concatenated_tensor)\n",
    "        rel = self.relu(h)\n",
    "        return rel\n",
    "\n",
    "class ExtendedAnomalyDetector(nn.Module):\n",
    "    \n",
    "    def __init__(self, anomaly_score_processor, anomaly_score_processor_dim, class_nr, device):\n",
    "        super(ExtendedAnomalyDetector, self).__init__()\n",
    "        self.anomaly_score_processor = anomaly_score_processor\n",
    "        self.output_layer = torch.nn.Linear(anomaly_score_processor_dim, class_nr).to(device)\n",
    "        self.softmax = torch.nn.Softmax().to(device)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.anomaly_score_processor(x)\n",
    "        h = self.output_layer(out)\n",
    "        return self.softmax(h)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp = AnomalyScoreProcessor(model, 8, 4, device)\n",
    "ead = ExtendedAnomalyDetector(asp, 4, 2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_extended_anomaly_detector(model, x_train, y_train, x_val, y_val, n_epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    history = dict(train=[], val=[])\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10000.0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model = model.train()\n",
    "        train_losses = []\n",
    "        for seq, y in zip(x_train, y_train):\n",
    "            optimizer.zero_grad()\n",
    "            seq = seq.to(device)\n",
    "            pred = model(seq)\n",
    "            #print(y)\n",
    "            loss = criterion(pred, torch.tensor(y).reshape(1).to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        val_losses = []\n",
    "        model = model.eval()\n",
    "        with torch.no_grad():\n",
    "            for seq, y in zip(x_val, y_val):\n",
    "                seq = seq.to(device)\n",
    "                pred = model(seq)\n",
    "                class_val = int(y>1)\n",
    "                loss = criterion(pred, torch.tensor(class_val).reshape(1).to(device))\n",
    "                val_losses.append(loss.item())\n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        history['train'].append(train_loss)\n",
    "        history['val'].append(val_loss)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model.eval(), history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_threshold = validation_errors.mean() + 3 * validation_errors.std()\n",
    "loss_f = torch.nn.L1Loss(reduction='sum').to(device)\n",
    "model = model.eval()\n",
    "losses = []\n",
    "training_y = []\n",
    "with torch.no_grad():\n",
    "    for seq_true in train_dataset:\n",
    "        seq_true = seq_true.to(device)\n",
    "        z, seq_pred = model(seq_true)\n",
    "        loss = loss_f(seq_pred, seq_true)\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(losses)\n",
    "sorted_losses = [losses[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = len(sorted_losses) - 1 \n",
    "while sorted_losses[i] > anomaly_threshold:\n",
    "    i-=1\n",
    "anomalies_cnt = len(sorted_losses) - 1 - i\n",
    "normal_data_index = i - anomalies_cnt\n",
    "normal_indices = indices[normal_data_index:i]\n",
    "anomaly_indices = indices[i:]\n",
    "\n",
    "artificial_train_dataset_X=[]\n",
    "artificial_train_dataset_y=[]\n",
    "labels = []\n",
    "\n",
    "for idx in normal_indices:\n",
    "    artificial_train_dataset_X.append(train_dataset[idx])\n",
    "    artificial_train_dataset_y.append(0)\n",
    "    labels.append(train_y.iloc[idx])\n",
    "\n",
    "for idx in anomaly_indices:\n",
    "    artificial_train_dataset_X.append(train_dataset[idx])\n",
    "    artificial_train_dataset_y.append(1)\n",
    "    labels.append(train_y.iloc[idx])\n",
    "artificial_train_dataset_y = pd.Series(artificial_train_dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    89\n",
       "0    88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artificial_train_dataset_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-77358d5482b9>:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 0.4717831423053634 val loss 0.39766698026657105\n",
      "Epoch 2: train loss 0.46625765703492245 val loss 0.39813790758450823\n",
      "Epoch 3: train loss 0.46634547824913497 val loss 0.3979583479563395\n",
      "Epoch 4: train loss 0.4655144319022443 val loss 0.3976763834158579\n",
      "Epoch 5: train loss 0.46460542840472724 val loss 0.39736603291829425\n",
      "Epoch 6: train loss 0.46369066750262417 val loss 0.3970482778549194\n",
      "Epoch 7: train loss 0.46278295442882905 val loss 0.39673129765192666\n",
      "Epoch 8: train loss 0.46188456729307015 val loss 0.3964190068244934\n",
      "Epoch 9: train loss 0.46099660086766475 val loss 0.39611343065897625\n",
      "Epoch 10: train loss 0.46011855373274807 val loss 0.39581513047218325\n",
      "Epoch 11: train loss 0.4592508074253966 val loss 0.39552419980367026\n",
      "Epoch 12: train loss 0.45839297704103976 val loss 0.3952411892414093\n",
      "Epoch 13: train loss 0.45754479621089783 val loss 0.3949666330019633\n",
      "Epoch 14: train loss 0.4567062275557868 val loss 0.39470053537686667\n",
      "Epoch 15: train loss 0.4558772953216639 val loss 0.39444227266311643\n",
      "Epoch 16: train loss 0.4550577705189333 val loss 0.3941917701562246\n",
      "Epoch 17: train loss 0.4542478329717776 val loss 0.39394900425275164\n",
      "Epoch 18: train loss 0.4534470166190196 val loss 0.3937140728632609\n",
      "Epoch 19: train loss 0.4526556093814009 val loss 0.3934867469469706\n",
      "Epoch 20: train loss 0.45187356411400487 val loss 0.39326670122146606\n",
      "Epoch 21: train loss 0.45110077608776633 val loss 0.3930536852677663\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-030ee6c960b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_extended_anomaly_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martificial_train_dataset_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martificial_train_dataset_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-61faed72e98a>\u001b[0m in \u001b[0;36mtrain_extended_anomaly_detector\u001b[0;34m(model, x_train, y_train, x_val, y_val, n_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mclass_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/FIT/lstm-ad/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-77358d5482b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manomaly_score_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/FIT/lstm-ad/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-77358d5482b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0manomaly_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mconcatenated_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomaly_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/FIT/lstm-ad/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/FIT/lstm-ad/lstmad/lstmae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/FIT/lstm-ad/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/FIT/lstm-ad/lstmad/lstmae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_n\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_n\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/FIT/lstm-ad/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/FIT/lstm-ad/.venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    570\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_extended_anomaly_detector(ead, artificial_train_dataset_X, artificial_train_dataset_y, val_dataset, val_y,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-77358d5482b9>:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(h)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "ead = ead.eval()\n",
    "with torch.no_grad():    \n",
    "    for seq in artificial_train_dataset_X:\n",
    "        seq = seq.to(device)\n",
    "        pred = ead(seq)\n",
    "        pred = np.argmax(pred.cpu().numpy())\n",
    "        preds.append(pred)\n",
    "preds = pd.Series(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8305084745762712"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(artificial_train_dataset_y == preds)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    123\n",
       "0     54\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=torch.zeros(8, dtype=float).reshape(1,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((a.reshape(1),b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reshaped = a.reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((a_reshaped, b), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
